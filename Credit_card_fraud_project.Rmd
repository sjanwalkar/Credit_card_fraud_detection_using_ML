---
title: "CREDIT CARD FRAUD DETECTION USING MACHINE LEARNING IN R"
output: word_document
@author : sachin.janwalkar@gmail.com
---


```{r}
# SL Project
# Credit Card Fraud detection.

# The datasets contains transactions made by credit cards in September 2013 by european cardholders.
# This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

# It contains only numerical input variables which are the result of a PCA transformation. 
# Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. 
# Features V1, V2, . V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. 
# Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.
# The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. 
# Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.

# Reading Data file
rm(list = ls())
input_data = read.csv("C:/Users/sachi/Desktop/MATH-569/Project- Credit card fraud detection/creditcard.csv")
```


```{r}


#********************** Performing data exploratory analysis to understand the data
str(input_data)
head(input_data)
tail(input_data)
dim(input_data)

# The data frame has 284807 rows and 31 columns.

summary(input_data)

table(input_data$Class)
# The data set is highly unbalances as it has 284315 non-fradulent and 492 fradulent transactions i.e. 0.173 %

barplot(table(input_data$Class),main="count of fradulent vs non-fradulent", xlab="0: Non-Fraudlent  1: Fradulent", ylab="count", col = 'blue')
```


```{r}
#visualizations of time and amount

plot(density(input_data$Time), main = "Density distibution Time")


plot(density(input_data$Amount), main = "Density distribution Amount")
#Around 88 dollars is the mean of all credit card transactions in this data set. The biggest transaction had a monetary value of around 25,691 dollars

```


```{r}
#************************ Feature scaling
# Correlation matrix

cor_matrix = round(cor(input_data),6)

#Correlation matrix heatmap
# library(ggplot2)
# cor_matrix = as.data.frame(cor_matrix)
# library(reshape2)
# melted_cormat <- melt(cor_matrix)
# ggplot(data = melted_cormat, aes(x=variable, y= variable, fill=value))+ geom_tile()

library(ggcorrplot)                                                      # Plotting correlation matrix diff format
ggcorrplot(cor_matrix)

```


```{r}
# Scaling amount and time

input_data$Time =scale(input_data$Time)
input_data$Amount= scale(input_data$Amount)



# Balancing the dataset

fraud_true = which(input_data$Class== 1)
fraud_false = which(input_data$Class == 0)
fraud_false_ds = sample(fraud_false,length(fraud_true))
subsample = input_data[c(fraud_false_ds,fraud_true),]                          # Balanced dataset subsample 
table(subsample$Class)
barplot(table(subsample$Class),main="count of fradulent vs non-fradulent", xlab="0: Non-Fraudlent  1: Fradulent", ylab="count", col = 'blue')


# checking for correlation in balanced subsample data
ggcorrplot(cor(subsample), type = "lower")
cor_subsample=cor(subsample)[,"Class"]
```


```{r}
# Checking for Correaltion >0.5 and <0.5
print("Features with high +ve correlation")
print(cor_subsample[cor_subsample>0.5])
print("Features with high -ve correlation")
print(cor_subsample[cor_subsample< (-0.5)])

# Box plots 
par(mfrow = c(1,2))
boxplot(subsample$Class,subsample$V4, names = c("Class","V4"), col = "gold")
boxplot(subsample$Class,subsample$V11, names = c("Class","V11"), col = "gold")



par(mfrow =c(3,3))
boxplot(subsample$Class,subsample$V3, names = c("Class","V3"), col = "gold")
boxplot(subsample$Class,subsample$V9, names = c("Class","V9"), col = "gold")
boxplot(subsample$Class,subsample$V10, names = c("Class","V10"), col = "gold")
boxplot(subsample$Class,subsample$V12, names = c("Class","V12"), col = "gold")
boxplot(subsample$Class,subsample$V14, names = c("Class","V14"), col = "gold")
boxplot(subsample$Class,subsample$V16, names = c("Class","V16"), col = "gold")
boxplot(subsample$Class,subsample$V17, names = c("Class","V17"), col = "gold")

```

# Removing the outliers

# One way to deal with outliers is by removing them as shown in the method below, Using quantile but for Credit card 
# fraud detection since these outliers are small in number we will procede as it is with running the outlier code:

# subsample_vector = c()                                           # Converting data frame to vector for quantile 
# for (i in 1:nrow(subsample)){
#   vec = as.numeric(subsample[i,1:ncol(subsample)])
#   subsample_vector = rbind(subsample_vector,vec)
#   
# }
# 
# colnames(subsample_vector) = names(subsample)
# rownames(subsample_vector) = row.names(subsample)
# 
# q = quantile(subsample_vector, probs=c(0.25,0.75),na.rm = FALSE )
# #q1 = quantile(subsample$V4,probs = c(0.25,0.75), na.rm = FALSE)            should do it for individual variables
# iqr = IQR(subsample_vector)                                  # IQR = Q3-Q1
# 
# up <-  q[2]+1.5*iqr                                          # Upper Range  
# low<- q[1]-1.5*iqr                                           # Lower Range???
# 
# cleaned_subsample = subset(subsample_vector, subsample_vector>low  && subsample_vector<up)



```{r}
# Class distribution in train and test data
set.seed(123)
split_size = floor(0.8*nrow(subsample))                                           # Defining split size 80% train 20% test
data_set = sample(seq_len(nrow(subsample)), size = split_size)                    # splitting the train test data
train_data = subsample[data_set,]
test_data = subsample[-data_set,]


print("Checking distribution of data ")
table(train_data$Class)                                 # checking the distribution of fraud and non-fraudulent trnsaction 
table(test_data$Class)

# Shuffling the dataset
rows_train = sample(nrow(train_data))
train_data = train_data[rows_train,]

rows_test = sample(nrow(test_data))
test_data =test_data[rows_test,]

# Seperating the input and the response variables
train_data_ip =train_data[,1:30]
train_data_op =train_data[,31]

test_data_ip = test_data[,1:30]
test_data_op = test_data[,31]

```



```{r}
# ****************** Fitting Models**************

# ****************** Logistic Regression****************
library(caTools)
logistic_model = glm(train_data$Class ~ ., data = train_data, family = binomial())
plot(logistic_model)

summary(logistic_model)
# Describe the summary

# prediction for the test data
predicted_data_lm = data.frame(probability.of.fraud =logistic_model$fitted.values, fraud =train_data$Class)
predicted_data_lm = predicted_data_lm[order(predicted_data_lm$probability.of.fraud, decreasing =  FALSE),]
predicted_data_lm$rank = 1:nrow(predicted_data_lm)

dev.off()
library(ggplot2)
library(cowplot)                         # for adding defaults to ggplot install package cowplot

ggplot(data = predicted_data_lm, aes(x=rank, y=probability.of.fraud))+
  geom_point(aes(color=fraud), alpha=1, shape =3, stroke=2)+
  xlab("Index")+
  ylab("Prediction probability of fraud")

# As it can be seen from the plot that logistic regression model has separated fraud from non-fradulent transactions 
# with some exception transactions, which can be seen in the overlap curve.

prob_logistic = predict(logistic_model, test_data_ip, type = 'response')
y_pred_logistic = as.factor(ifelse(prob_logistic>0.5, 1,0))
print("Logistic Regression")
table(test_data_op, y_pred_logistic, dnn=c('Actual values','Predicted values'))
accuracy_logistic=mean(y_pred_logistic==test_data_op)

# As it can be seen from the plot Logistic model has done quite a good job in classifying most of the 
# transaction in fraud and non-fraudulent ones. Except some transactions which can be seen as different 
# coloring in the color scale
```



```{r}
# *************** Discriminant Analysis*********************
library(MASS)
lda_model = lda(train_data$Class~.,data = train_data)
predicted_data_lda = predict(lda_model, newdata = test_data_ip)
accuracy_lda =mean(predicted_data_lda$class == test_data_op)                                                # calculation prediction accuracy on the test data
print('LDA Analysis')
table(predicted_data_lda$class ,test_data_op, dnn = c('predicted values','Actual Values'))     # confusion matrix
```

```{r}
qda_model =qda(train_data$Class~., data = train_data)
predicted_data_qda = predict(qda_model, newdata = test_data_ip)
accuracy_qda=mean(predicted_data_qda$class == test_data_op)                                                # calculation prediction accuracy on the test data         
print('QDA Analysis')
table(predicted_data_qda$class ,test_data_op, dnn = c('predicted values','Actual Values'))    # confusion matrix
```


```{r}
#******************** KNN ********************************
library(class)
knn_model = knn(train = train_data, test = test_data, cl=train_data_op, k =10)
accuracy_knn=mean(test_data_op == knn_model)                                              # calculation prediction accuracy on the test data
print('KNN Algorithm')
table(test_data_op, knn_model, dnn = c('Actual values', 'Predicted values'))      # confusion matrix
```


```{r}
#********************  Neural Network*********************

library(neuralnet)
ann_model = neuralnet(train_data$Class~.,data = train_data, linear.output = FALSE)
plot(ann_model)
pred_ann = compute(ann_model, test_data_ip)
result_ann = pred_ann$net.result
result_ann=ifelse(result_ann>0.5,1,0)
accuracy_NN= mean(result_ann==test_data_op)                    # calculation prediction accuracy on the test data
table(test_data_op, result_ann, dnn = c('Actual values', 'Predicted values'))           # confusion matrix

# Accuracy on Neural Network can be enhanced by optimizing its hyperparameters such as no of hidden layers or neurons in each layer
```


```{r}
#******************** DCT *********************


library(rpart)
library(rpart.plot)
decisiontree_model <- rpart(train_data$Class~., data = train_data, method = 'class')
rpart.plot(decisiontree_model)

decisiontree_prediction = predict(decisiontree_model, test_data_ip, type = 'class')
accuracy_dtree=mean(decisiontree_prediction == test_data_op)       # calculation prediction accuracy on the test data
table(test_data_op, decisiontree_prediction, dnn = c('Actual values', 'Predicted values'))   # confusion matrix
```


```{r}
#********************* Gradient Boosting***********

library(gbm)
gradientboost_model = gbm(subsample$Class~., 
                          distribution = 'bernoulli',
                          data = subsample,
                          n.trees = 200,
                          interaction.depth = 3,
                          n.minobsinnode = 100,
                          shrinkage = 0.01,
                          bag.fraction = .5,
                          train.fraction = nrow(train_data)/nrow(subsample))

gradientboost_iter= gbm.perf(gradientboost_model, method = 'test')

plot(gradientboost_model)

gradientboost_predict = predict(gradientboost_model, newdata = test_data_ip, n.trees = gradientboost_iter)
library(pROC)
gradientboost_auc = roc(test_data_op, gradientboost_predict, plot=TRUE, col='Blue')
print(gradientboost_auc)
accuracy_boosting=0.9687


# As it can be seen the AUC value is 0.9687 which means that the classifier is excellent.
```


```{r}
# Working with unbalance dataset
# ****************** Isolation Forest Algorithm******************8
n =0.1*nrow(input_data)
set.seed(10)
input_data1 = input_data[sample(nrow(input_data),n) ,]
table(input_data1$Class==0, input_data1$Class==1)         # checking the distribution in the new data
index = sample(nrow(input_data1)*0.8)

library(solitude)


iso_model = isolationForest$new(
  sample_size = length(index),
  num_trees = 100,
  replace = FALSE,
  seed = 101,
  nproc = NULL,
  respect_unordered_factors = NULL,
)
iso_model$fit(dataset = input_data1[index,])
predict1= iso_model$predict(input_data1[index,])
predict2 = iso_model$predict(input_data1[-index, ])
y_predcit = as.factor(ifelse(predict2$anomaly_score>=0.61,1,0))
accuracy_isoforest=mean(input_data1[-index,]$Class==y_predcit)
```


```{r}
#********************* prediction Accuracy Table************
a = c('Logistic Regression','LDA','QDA','KNN','Neural Network','Decision Tree','Gradient Boost', 'Isolation Forest')
b = c(accuracy_logistic, accuracy_lda, accuracy_qda, accuracy_knn, accuracy_NN, accuracy_dtree, accuracy_boosting, accuracy_isoforest)
accuracy_table = data.frame("ML Algorithm"= a, "Accuracy"=b)
print(accuracy_table)

# plotting the Accuracy values

ggplot(data=accuracy_table, aes(x= a, y=b, color="red"))+geom_boxplot()+
  xlab("ML Algorithm")+
  ylab("Accuracy")
```


# ********************* LOF********************

install.packages("Rlof")
library(Rlof)

help(lof)
lof_model = lof(input_data1[,1:30], k=5)
# memory.size()
# memory.limit()                        # changing the limit
quantile(lof_model)
thr = quantile(mlof, .97)             # setting the threshold
predcit_lof = as.factor(ifelse(lof_model>=thr,1,0))

# Cannot perform Local classifier Factor Algorithm because of the following error:
# Error: cannot allocate vector of size 6.0 Gb
# Tried changing the memory allocation limit but still the same error persist



